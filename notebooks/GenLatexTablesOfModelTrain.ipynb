{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "\n",
    "ENTITY = \"confopt-team\"\n",
    "PROJECT = \"ConfoptAutoML25-Models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_run_data(run_id, entity=\"confopt-team\", project=\"ConfoptAutoML25-Models\"):\n",
    "    \"\"\"\n",
    "    Pull data from a W&B run given the entity, project, and run_id.\n",
    "    \n",
    "    Args:\n",
    "        entity (str): The W&B entity (username or team).\n",
    "        project (str): The name of the W&B project.\n",
    "        run_id (str): The run identifier.\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary containing the run summary, config, and history (as a pandas DataFrame).\n",
    "    \"\"\"\n",
    "    api = wandb.Api()\n",
    "    run_path = f\"{entity}/{project}/{run_id}\"\n",
    "    try:\n",
    "        run = api.run(run_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving run: {e}\")\n",
    "        return None\n",
    "\n",
    "    # Retrieve summary metrics (as a dict)\n",
    "    summary = run.summary._json_dict\n",
    "\n",
    "    # Retrieve configuration used for the run\n",
    "    config = run.config\n",
    "\n",
    "    # Retrieve run history (logged metrics) as a pandas DataFrame\n",
    "    # history = run.history(pandas=True)\n",
    "\n",
    "    return {\"summary\": summary, \"config\": config} # \"history\": history}\n",
    "\n",
    "def get_run_ids_with_filter(filter_dict, entity=\"confopt-team\", project=\"ConfoptAutoML25-models\"):\n",
    "    \"\"\"\n",
    "    Retrieve the run IDs for all runs in a project that match the given filter.\n",
    "\n",
    "    Args:\n",
    "        entity (str): The W&B entity (username or team).\n",
    "        project (str): The name of the W&B project.\n",
    "        filter_dict (dict): A dictionary defining the filter criteria.\n",
    "            For example: {\"config.learning_rate\": 0.001}\n",
    "    \n",
    "    Returns:\n",
    "        list: A list of run IDs that match the filter.\n",
    "    \"\"\"\n",
    "    api = wandb.Api()\n",
    "    runs = api.runs(f\"{entity}/{project}\", filters=filter_dict)\n",
    "    run_ids = [run.id for run in runs]\n",
    "    run_names = [run.name for run in runs]\n",
    "    return run_ids, run_names\n",
    "\n",
    "def print_wandb_links(run_ids, run_names, entity=ENTITY, project=PROJECT):\n",
    "    for run_id, run_name in zip(run_ids, run_names):\n",
    "        print(f\"https://wandb.ai/{entity}/{project}/runs/{run_id}/overview ({run_name} {run_id})\")\n",
    "\n",
    "def get_list_of_incomplete_runs(results, optimizer, optimizer_other, opset, subspace, fingerprint_cols, seed=0):\n",
    "    # Filter the results DataFrame based on the query parameters\n",
    "    filtered_results = results[\n",
    "        (results['optimizer'] == optimizer) &\n",
    "        (results['optimizer_other'] == optimizer_other) &\n",
    "        (results['opset'] == opset) &\n",
    "        (results['subspace'] == subspace) &\n",
    "        (results['seed'] == seed)\n",
    "    ]\n",
    "\n",
    "    incomplete_runs = []\n",
    "\n",
    "    # Check if there are exactly nine rows\n",
    "    if len(filtered_results) == 9:\n",
    "        # Check if the only column that is different is hyperparameter_set\n",
    "        unique_hyperparameter_sets = filtered_results['hyperparameter_set'].nunique()\n",
    "        if unique_hyperparameter_sets == 9:\n",
    "            # Check if all other columns (excluding those starting with '_') are identical\n",
    "            identical = all(filtered_results[fingerprint_cols].nunique() == 1)\n",
    "            if identical:\n",
    "                # print(\"Experiment complete!\")\n",
    "                incomplete_runs = None\n",
    "            else:\n",
    "                print(\"Rows are not identical!\")\n",
    "                incomplete_runs = []\n",
    "        else:\n",
    "            print(\"There are exactly nine rows, but other columns are also different.\")\n",
    "            incomplete_runs = []\n",
    "            \n",
    "    else:\n",
    "        # print(f\"Only {len(filtered_results)}/9 runs complete.\")\\\n",
    "        incomplete_runs = list(set(range(9)) - set(filtered_results['hyperparameter_set']))\n",
    "        print(\"Duplicate runs!\")\n",
    "    \n",
    "    return incomplete_runs\n",
    "    \n",
    "\n",
    "def get_result_for_exp(results_df, optimizer, optimizer_other, subspace, opset, seed):\n",
    "    return results_df[\n",
    "        (results_df['optimizer'] == optimizer) &\n",
    "        (results_df['optimizer_other'] == optimizer_other) &\n",
    "        (results_df['subspace'] == subspace) &\n",
    "        (results_df['opset'] == opset) &\n",
    "        (results_df['seed'] == seed)\n",
    "    ].sort_values(by='hyperparameter_set')\n",
    "\n",
    "\n",
    "def beautify_table(results_table):\n",
    "    method_label_mapping = {\n",
    "        \"darts\": \"DARTS\",\n",
    "        \"drnas\": \"DRNAS\",\n",
    "        \"gdas\": \"GDAS\",\n",
    "        \"pcdarts\": \"PC-DARTS\",\n",
    "        \"sdarts\": \"SDARTS\",\n",
    "        \"fairdarts\": \"FairDARTS\",\n",
    "        \"oles\": \"OLES\",\n",
    "    }\n",
    "\n",
    "    space_label_mapping = {\n",
    "        \"deep\": \"Deep\",\n",
    "        \"wide\": \"Wide\",\n",
    "        \"single_cell\": \"Single Cell\",\n",
    "    }\n",
    "\n",
    "    opset_label_mapping = {\n",
    "        \"regular\": \"Regular\",\n",
    "        \"all_skip\": \"All Skip\",\n",
    "        \"no_skip\": \"No Skip\",\n",
    "    }\n",
    "\n",
    "    df = results_table.copy()\n",
    "    df['Test Accuracy (%)'] = df.apply(lambda row: f\"{row['mean']:.2f} Â± {row['std']:.2f}\", axis=1)\n",
    "    df['Maximum Test Accuracy (%)'] = df[\"max\"]\n",
    "    df[\"Method\"] = df[\"optimizer\"]\n",
    "    df[\"Method\"] = df[\"Method\"].apply(lambda x: method_label_mapping[x])\n",
    "    df[\"Operation Set\"] = df[\"opset\"].apply(lambda x: opset_label_mapping[x])\n",
    "    df[\"Subspace\"] = df[\"subspace\"].apply(lambda x: space_label_mapping[x])\n",
    "    df.sort_values(by=list(reversed([\"Method\", \"Subspace\", \"Operation Set\"])), inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def generate_latex_table(results_table):\n",
    "    # Select the columns you want to include in the table\n",
    "    columns = [\"Method\", \"Subspace\", \"Operation Set\", \"Test Accuracy (%)\", \"Maximum Test Accuracy (%)\"]\n",
    "\n",
    "    # Filter the DataFrame to include only the selected columns\n",
    "    latex_df = beautify_table(results_table)[columns]\n",
    "\n",
    "    # Convert the DataFrame to a LaTeX table\n",
    "    latex_table = tabulate(latex_df, headers='keys', tablefmt='latex', showindex=False)\n",
    "\n",
    "    # Print the LaTeX table\n",
    "    print(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_dict = {\n",
    "    # \"config.subspace\": subspace,\n",
    "    # \"config.opset\": opset,\n",
    "    # \"config.dataset\": dataset,\n",
    "    \"config.optimizer\": {\"$in\": [\"darts\", \"gdas\", \"drnas\"]},\n",
    "    # \"config.optimizer_other\": optimizer_other,\n",
    "    # \"config.trainer.batch_size\": batch_size,\n",
    "    # \"config.tag\": {\"$in\": [\n",
    "    #     \"models-train\",\n",
    "    #     \"models-train-mixed-hps\",\n",
    "    #     \"models-train-batch3\",\n",
    "    #     \"models-train-batch4\",\n",
    "    #     \"models-train-batch5\",\n",
    "    #     ]},\n",
    "    \"config.lr\": {\"$ne\": 0.001},\n",
    "    \"summary_metrics._step\": 300,\n",
    "    \"state\": \"finished\",\n",
    "}\n",
    "\n",
    "print(filter_dict)\n",
    "run_ids, run_names = get_run_ids_with_filter(filter_dict)\n",
    "\n",
    "len(run_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_run_data = []\n",
    "\n",
    "for run_id in run_ids:\n",
    "    # print(run_id)\n",
    "    run_data = pull_run_data(run_id)\n",
    "    data = run_data[\"config\"]\n",
    "    data.update(run_data[\"summary\"])\n",
    "\n",
    "    all_run_data.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(all_run_data)\n",
    "fingerprint_cols = [\"optimizer\", \"optimizer_other\", \"subspace\", \"opset\", \"genotype\", \"dataset\", \"seed\", \"_step\"]\n",
    "results_df[fingerprint_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv('complete_model_runs.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplers = (\"darts\", \"drnas\", \"gdas\")\n",
    "subspaces = (\"deep\", \"wide\", \"single_cell\")\n",
    "opsets = (\"regular\", \"all_skip\", \"no_skip\")\n",
    "darts_others = (\"baseline\", \"oles\", \"pcdarts\", \"sdarts\", \"fairdarts\")\n",
    "\n",
    "all_incomplete_runs = {}\n",
    "n_incomplete_runs = 0\n",
    "n_complete_runs = 0\n",
    "\n",
    "n = 0\n",
    "\n",
    "exps_complete = []\n",
    "\n",
    "for sampler in samplers:\n",
    "    for subspace in subspaces:\n",
    "        for opset in opsets:\n",
    "\n",
    "            others = darts_others if sampler == \"darts\" else (\"baseline\",)\n",
    "\n",
    "            for other in others:\n",
    "                n += 1\n",
    "                incomplete_runs = get_list_of_incomplete_runs(\n",
    "                    results_df,\n",
    "                    sampler,\n",
    "                    other,\n",
    "                    opset,\n",
    "                    subspace,\n",
    "                    fingerprint_cols,\n",
    "                    seed=0\n",
    "                )\n",
    "                model = f\"{sampler}-{other}-{subspace}-{opset}\"\n",
    "\n",
    "                if incomplete_runs is None:\n",
    "                    print(model, \"\\t\\tAll runs complete!\")\n",
    "                    n_complete_runs += 9\n",
    "                    m = {\n",
    "                        \"optimizer\": sampler,\n",
    "                        \"optimizer_other\": other,\n",
    "                        \"subspace\": subspace,\n",
    "                        \"opset\": opset,\n",
    "                        \"seed\": 0,\n",
    "                    }\n",
    "                    exps_complete.append(m)\n",
    "                elif len(incomplete_runs) > 0:\n",
    "                    print(model, f\"\\t\\tIncomplete runs: {incomplete_runs}\")\n",
    "                    all_incomplete_runs[model] = incomplete_runs\n",
    "                    n_incomplete_runs += len(incomplete_runs)\n",
    "                    n_complete_runs += (9 - len(incomplete_runs))\n",
    "                else:\n",
    "                    print(model, \"\\t\\tIt's complicated.\")\n",
    "\n",
    "print(f\"Total incomplete runs: {n_incomplete_runs}\")\n",
    "print(f\"Total complete runs: {n_complete_runs}/{n*9}\")\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_rows = []\n",
    "\n",
    "for exp in exps_complete:\n",
    "    # print(exp)\n",
    "    exp_results = get_result_for_exp(results_df, **exp).describe()[\"discrete/test/acc_top1\"]\n",
    "    mean, std, mx = exp_results[\"mean\"], exp_results[\"std\"], exp_results[\"max\"]\n",
    "    print(exp, mean, std, mx)\n",
    "\n",
    "    row_data = {k:v for k,v in exp.items()}\n",
    "\n",
    "    optimizer = row_data[\"optimizer\"]\n",
    "    optimizer_other = row_data[\"optimizer_other\"]\n",
    "    if optimizer == \"darts\" and optimizer_other != \"baselines\":\n",
    "        row_data[\"optimizer_other\"] = optimizer_other\n",
    "    \n",
    "    row_data[\"mean\"] = mean\n",
    "    row_data[\"std\"] = std\n",
    "    row_data[\"max\"] = mx\n",
    "    all_rows.append(row_data)\n",
    "\n",
    "results_table = pd.DataFrame(all_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_latex_table(results_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_incomplete_runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in all_incomplete_runs.items():\n",
    "    opt, other, space, opset = k.split(\"-\")\n",
    "    hpsets = set(v) | set((3,4,5))\n",
    "    hpsets = \",\".join(sorted(str(x) for x in hpsets))\n",
    "\n",
    "    print(f\"python launch_model_train.py --optimizer {opt} --subspace {space} --opset {opset} --dataset cifar10_model --hpsets {hpsets} --seed 0 --epochs 300 --other {other} --tag models-train --genotypes_folder exp/genotypes & sleep 5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exps_complete[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for experiment in exps_complete:\n",
    "    opt, other, space, opset = experiment[\"optimizer\"], experiment[\"optimizer_other\"], experiment[\"subspace\"], experiment[\"opset\"]\n",
    "    hpsets = \"3,4,5\"\n",
    "    # hpsets = \",\".join(sorted(str(x) for x in hpsets))\n",
    "\n",
    "    print(f\"python launch_model_train.py --optimizer {opt} --subspace {space} --opset {opset} --dataset cifar10_model --hpsets {hpsets} --seed 0 --epochs 300 --other {other} --tag models-train --genotypes_folder exp/genotypes & sleep 5\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "confopt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
