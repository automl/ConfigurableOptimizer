{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "FINGERPRINT_COLS = ['optimizer', 'optimizer_other', 'subspace', 'opset']\n",
    "HPSET = \"hyperparameter_set\"\n",
    "TAG = \"tag\"\n",
    "TAG_MIXED_HPS = \"models-train-mixed-hps\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"complete_model_runs.csv\")\n",
    "df.columns, len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tag.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = df.groupby(['optimizer', 'optimizer_other', 'subspace', 'opset'])\n",
    "group_counts = grouped_df.size()\n",
    "group_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_hyperparameter_sets = grouped_df['hyperparameter_set'].nunique()\n",
    "incomplete_runs_groups = unique_hyperparameter_sets[unique_hyperparameter_sets != 9]\n",
    "incomplete_runs_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_missing = 0\n",
    "missing_runs = []\n",
    "for name, group in grouped_df:\n",
    "    if name in incomplete_runs_groups.index:\n",
    "        missing = set(range(9)) - set(group[\"hyperparameter_set\"].unique())\n",
    "        print(f\"Group: {name}\", missing)\n",
    "        n_missing += len(missing)\n",
    "        missing_runs.append((name, missing))\n",
    "\n",
    "print(n_missing, missing_runs)\n",
    "\n",
    "for config, hpsets in missing_runs:\n",
    "    optimizer, optimizer_other, subspace, opset = config\n",
    "    for hp in hpsets:\n",
    "        print(f\"python launch_model_train.py --optimizer {optimizer} --subspace {subspace} --opset {opset} --dataset cifar10_model --hpsets {hp} --seed 0 --epochs 300 --other {optimizer_other} --tag models-train-batch7 --genotypes_folder exp/genotypes & sleep 5\")\n",
    "    \n",
    "n_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_runs_dfs = grouped_df.filter(lambda x: len(x) > 9)\n",
    "grouped_duplicate_dfs = duplicate_runs_dfs.groupby(['optimizer', 'optimizer_other', 'subspace', 'opset'])\n",
    "grouped_duplicate_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_duplicate_tag_groups = []\n",
    "\n",
    "for name, group in grouped_duplicate_dfs:\n",
    "    print(name, len(group))\n",
    "    # print(group[\"hyperparameter_set\"])\n",
    "    duplicates = group[group.duplicated(subset=['hyperparameter_set'], keep=False)]\n",
    "    hpsets = set(duplicates[\"hyperparameter_set\"])\n",
    "\n",
    "    for hp in hpsets:\n",
    "        duplicates_hp = duplicates[duplicates[\"hyperparameter_set\"] == hp]\n",
    "        duplicate_tags = sorted(set(duplicates_hp[\"tag\"]))\n",
    "        if len(duplicate_tags) == 1:\n",
    "            single_duplicate_tag_groups.append((name, hp))\n",
    "        print(hp, duplicate_tags, \"ONLY ONE!!!\" if len(set(duplicates_hp[\"tag\"])) == 1 else \"\")\n",
    "\n",
    "single_duplicate_tag_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by all columns except 'tag'\n",
    "grouped = df.groupby(['optimizer', 'optimizer_other', 'opset', 'subspace', 'hyperparameter_set', 'seed'])\n",
    "\n",
    "# Filter groups where the only difference is the 'tag'\n",
    "filtered_groups = grouped.filter(lambda x: len(x[TAG].unique()) > 1)\n",
    "mixed_hp_df = filtered_groups[filtered_groups[TAG] == TAG_MIXED_HPS]\n",
    "mixed_hp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_runs_df = grouped_df.filter(lambda x: len(x) == 9)\n",
    "complete_runs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_runs_df = df.groupby(FINGERPRINT_COLS).filter(lambda x: len(x) == 9)\n",
    "len(complete_runs_df) // 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incomplete_runs_df = df.groupby(FINGERPRINT_COLS).filter(lambda x: len(x) < 9)\n",
    "incomplete_runs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_runs_df = df.groupby(FINGERPRINT_COLS).filter(lambda x: len(x) > 9)\n",
    "duplicate_runs_groups = duplicate_runs_df.groupby(FINGERPRINT_COLS)\n",
    "print(len(duplicate_runs_groups))\n",
    "duplicate_runs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rows to drop by picked the earliest runs (from tag train-models-mixed-hp)\n",
    "rows_to_drop = []\n",
    "\n",
    "for index, data in duplicate_runs_groups:\n",
    "    hp_freq = data[HPSET].value_counts() > 1\n",
    "    for hp, is_duplicate in hp_freq.items():\n",
    "\n",
    "        if is_duplicate:\n",
    "            rows = data[data[HPSET] == hp]\n",
    "            if(TAG_MIXED_HPS in rows[TAG].values):\n",
    "                rows_to_delete = data[(data[HPSET] == hp) & (data[TAG] != TAG_MIXED_HPS)]\n",
    "                rows_to_drop.append(rows_to_delete.index.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deduplicated_runs_groups = df.drop(rows_to_drop).groupby(FINGERPRINT_COLS).filter(lambda x: len(x) > 9).groupby(FINGERPRINT_COLS)\n",
    "deduplicated_runs_groups.size()\n",
    "\n",
    "# Rows to drop by picked the earliest runs which have to be picked by hand\n",
    "# Populating the array is just for convenience\n",
    "rows_to_delete_ = []\n",
    "for index, data in deduplicated_runs_groups:\n",
    "    hp_freq = data[HPSET].value_counts() > 1\n",
    "    for hp, is_duplicate in hp_freq.items():\n",
    "\n",
    "        if is_duplicate:\n",
    "            rows = data[data[HPSET] == hp]\n",
    "            print(rows[[HPSET, TAG]])\n",
    "            # if len(set(rows[TAG])) == 1:\n",
    "            rows_to_delete_.append(rows.index[0])\n",
    "\n",
    "rows_to_delete_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = df.drop(rows_to_drop + rows_to_delete_).groupby(FINGERPRINT_COLS).filter(lambda x: len(x) == 9)\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.groupby(FINGERPRINT_COLS).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(rows_to_drop + rows_to_delete_).groupby(FINGERPRINT_COLS).filter(lambda x: len(x) < 9).groupby(FINGERPRINT_COLS).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADDITIONAL_COLS = [\"hyperparameter_set\", \"discrete/test/acc_top1\", \"discrete/test/acc_top5\"]\n",
    "refined_df = final_df.copy()[FINGERPRINT_COLS + ADDITIONAL_COLS]\n",
    "refined_df[\"Optimizer\"] = refined_df[\"optimizer\"]\n",
    "refined_df[\"Subspace\"] = refined_df[\"subspace\"]\n",
    "refined_df[\"Opset\"] = refined_df[\"opset\"]\n",
    "refined_df[\"HP_Idx\"] = refined_df[\"hyperparameter_set\"]\n",
    "refined_df[\"TestAcc1\"] = refined_df[\"discrete/test/acc_top1\"]\n",
    "refined_df[\"TestAcc5\"] = refined_df[\"discrete/test/acc_top5\"]\n",
    "\n",
    "refined_df[\"Optimizer\"] = refined_df.apply(lambda row: row[\"optimizer_other\"] if row[\"optimizer_other\"] != \"baseline\" else row[\"optimizer\"], axis=1)\n",
    "refined_df = refined_df.drop(FINGERPRINT_COLS + ADDITIONAL_COLS, axis=1)\n",
    "refined_df\n",
    "\n",
    "refined_df.to_csv(\"model_trains_full.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refined_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "confopt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
