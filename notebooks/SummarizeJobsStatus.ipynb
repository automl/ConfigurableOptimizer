{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import pandas as pd\n",
    "\n",
    "def get_run_ids_with_filter(entity, project, filter_dict):\n",
    "    \"\"\"\n",
    "    Retrieve the run IDs for all runs in a project that match the given filter.\n",
    "\n",
    "    Args:\n",
    "        entity (str): The W&B entity (username or team).\n",
    "        project (str): The name of the W&B project.\n",
    "        filter_dict (dict): A dictionary defining the filter criteria.\n",
    "            For example: {\"config.learning_rate\": 0.001}\n",
    "    \n",
    "    Returns:\n",
    "        list: A list of run IDs that match the filter.\n",
    "    \"\"\"\n",
    "    api = wandb.Api()\n",
    "    runs = api.runs(f\"{entity}/{project}\", filters=filter_dict)\n",
    "    run_ids = [run.id for run in runs]\n",
    "    run_names = [run.name for run in runs]\n",
    "    return run_ids, run_names\n",
    "\n",
    "def pull_run_data(run_id, entity=\"confopt-team\", project=\"ConfoptAutoML25\"):\n",
    "    \"\"\"\n",
    "    Pull data from a W&B run given the entity, project, and run_id.\n",
    "    \n",
    "    Args:\n",
    "        entity (str): The W&B entity (username or team).\n",
    "        project (str): The name of the W&B project.\n",
    "        run_id (str): The run identifier.\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary containing the run summary, config, and history (as a pandas DataFrame).\n",
    "    \"\"\"\n",
    "    api = wandb.Api()\n",
    "    run_path = f\"{entity}/{project}/{run_id}\"\n",
    "    try:\n",
    "        run = api.run(run_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving run: {e}\")\n",
    "        return None\n",
    "\n",
    "    # Retrieve summary metrics (as a dict)\n",
    "    summary = run.summary._json_dict\n",
    "\n",
    "    # Retrieve configuration used for the run\n",
    "    config = run.config\n",
    "\n",
    "    # Retrieve run history (logged metrics) as a pandas DataFrame\n",
    "    # history = run.history(pandas=True)\n",
    "    history = {}\n",
    "\n",
    "    return {\"summary\": summary, \"config\": config, \"history\": history, \"run_name\": run.name}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace these with your actual values\n",
    "entity = \"confopt-team\"\n",
    "project = \"ConfoptAutoML25\"\n",
    "\n",
    "# Define your filter. For example, filtering runs with a specific learning rate.\n",
    "filter_dict = {\n",
    "    # \"config.benchmark\": \"deep-regular\",\n",
    "    # \"config.dataset\": \"cifar10\",\n",
    "    # \"config.sampler_type\": \"darts\",\n",
    "    \"config.tag\": \"first-full-run\", #\"first-full-run\",\n",
    "    # \"benchmark\": \"single_cell-no_skip\",\n",
    "    \"config.trainer.batch_size\": {\"$in\": [64, 96, 480, 320]},\n",
    "    \"config.is_debug_run\": False,\n",
    "    \"state\": \"finished\",\n",
    "}\n",
    "\n",
    "# Retrieve the run IDs matching the filter\n",
    "matching_run_ids, matching_run_names = get_run_ids_with_filter(entity, project, filter_dict)\n",
    "print(f\"Matching run IDs: {matching_run_ids}\")\n",
    "print(f\"Matching run names: {matching_run_names}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(matching_run_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas = dict()\n",
    "\n",
    "for run_id, run_name in zip(matching_run_ids, matching_run_names):\n",
    "    print(\"Loading data for run:\", run_name)\n",
    "    data = pull_run_data(run_id)\n",
    "    datas[run_id] = data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datas[\"8wovcbhs\"]\n",
    "config = data[\"config\"]\n",
    "\n",
    "\n",
    "def get_row_data(config):\n",
    "    optimizer = config[\"sampler_type\"]\n",
    "    space = config[\"space\"]\n",
    "    opset = config[\"opset\"]\n",
    "\n",
    "    pcdarts = config[\"partial_connector\"] is not None\n",
    "    oles = config[\"oles\"][\"oles\"] is True\n",
    "    fairdarts = config[\"sampler\"][\"arch_combine_fn\"] == \"sigmoid\"\n",
    "    sdarts = config[\"perturbator\"] is not None\n",
    "    seed = config[\"trainer\"][\"seed\"]\n",
    "    batch_size = config[\"trainer\"][\"batch_size\"]\n",
    "    weight_type = \"ws\" if config[\"weight_type\"] == \"weight_sharing\" else \"we\"\n",
    "    is_debug_run = config[\"is_debug_run\"]\n",
    "\n",
    "    exp_summary = f\"{optimizer}_{space}_{opset}_\"\n",
    "    exp_extra = f\"{'pcdarts_' if pcdarts else ''}{'oles_' if oles else ''}{'fairdarts_' if fairdarts else ''}{'sdarts_' if sdarts else ''}\"\n",
    "    exp_seed = f\"seed-{seed}\"\n",
    "    exp_batch_size = f\"batch-{batch_size}_\"\n",
    "    exp_weight_type = f\"{weight_type}_\"\n",
    "    exp_is_debug_run = f\"debug\" if is_debug_run else \"\"\n",
    "    exp_name = f\"{exp_summary}{exp_extra}{exp_weight_type}{exp_batch_size}{exp_seed}{exp_is_debug_run}\"\n",
    "\n",
    "    row = {\n",
    "        \"run_name\": data[\"run_name\"],\n",
    "        # \"exp_name\": exp_name,\n",
    "        \"optimizer\": optimizer,\n",
    "        \"space\": space,\n",
    "        \"opset\": opset,\n",
    "        \"pcdarts\": pcdarts,\n",
    "        \"oles\": oles,\n",
    "        \"fairdarts\": fairdarts,\n",
    "        \"sdarts\": sdarts,\n",
    "        \"seed\": seed,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"weight_type\": weight_type,\n",
    "        \"is_debug_run\": is_debug_run,\n",
    "    }\n",
    "\n",
    "    return row  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([get_row_data(data[\"config\"]) for data in datas.values()])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(df, optimizer, space, opset, oles, sdarts, fairdarts, pcdarts, weight_type, is_debug_run=False):\n",
    "    return df[(df[\"oles\"] == oles) & (df[\"sdarts\"] == sdarts) & (df[\"fairdarts\"] == fairdarts) & (df[\"pcdarts\"] == pcdarts) & (df[\"space\"] == space) & (df[\"opset\"] == opset) & (df[\"optimizer\"] == optimizer) & (df[\"weight_type\"] == weight_type) & (df[\"is_debug_run\"] == is_debug_run)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_if_incomplete(results, optimizer, space, opset, extra):\n",
    "    all_seeds = set(range(0, 3))\n",
    "    if len(results) < 3:\n",
    "        print(f\"{optimizer} {space} {opset} {extra}\", len(results), \"\\t\\t\\t\\tMissing seeds:\", all_seeds - set(results[\"seed\"])) \n",
    "\n",
    "for optimizer in (\"darts\", \"drnas\", \"gdas\"):\n",
    "    for space in (\"deep\", \"wide\", \"single_cell\"):\n",
    "        for opset in (\"no_skip\", \"all_skip\", \"regular\"):\n",
    "            results = get_results(df, optimizer, space, opset, oles=False, sdarts=False, fairdarts=False, pcdarts=False, weight_type=\"ws\")\n",
    "            print_if_incomplete(results, optimizer, space, opset, \"baseline\")\n",
    "\n",
    "            if optimizer == \"darts\":\n",
    "                results = get_results(df, optimizer, space, opset, oles=True, sdarts=False, fairdarts=False, pcdarts=False, weight_type=\"ws\")\n",
    "                print_if_incomplete(results, optimizer, space, opset, \"oles\")\n",
    "\n",
    "                results = get_results(df, optimizer, space, opset, oles=False, sdarts=True, fairdarts=False, pcdarts=False, weight_type=\"ws\")\n",
    "                print_if_incomplete(results, optimizer, space, opset, \"sdarts\")\n",
    "\n",
    "                results = get_results(df, optimizer, space, opset, oles=False, sdarts=False, fairdarts=True, pcdarts=False, weight_type=\"ws\")\n",
    "                print_if_incomplete(results, optimizer, space, opset, \"fairdarts\")\n",
    "\n",
    "                results = get_results(df, optimizer, space, opset, oles=False, sdarts=False, fairdarts=False, pcdarts=True, weight_type=\"ws\")\n",
    "                print_if_incomplete(results, optimizer, space, opset, \"pcdarts\")\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for run_id, data in datas.items():\n",
    "    run_name = data[\"run_name\"]\n",
    "    summary = data[\"summary\"]\n",
    "    config = data[\"config\"]\n",
    "\n",
    "    runtime = summary[\"_runtime\"]\n",
    "    epoch = summary[\"_step\"]\n",
    "    time_per_epoch = runtime / epoch\n",
    "\n",
    "    total_epochs = config[\"trainer\"][\"epochs\"]\n",
    "    time_left = (total_epochs - epoch) * time_per_epoch\n",
    "    will_finish = (total_epochs - epoch) * time_per_epoch + runtime < 24 * 3600\n",
    "\n",
    "    print(f\"Run ID: {run_id}, time per epoch: {time_per_epoch:7.2f} \\truntime: {runtime:8.02f}\\tepoch: {epoch:3}/{total_epochs:3} \\ttime left: {time_left/3600:6.2f} \\twill finish: {will_finish} \\trun_name: {run_name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "confopt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
